---
title: "HW: Week 3"
author: "36-350 -- Statistical Computing"
date: "Week 3 -- Spring 2022"
output:
  pdf_document:
    toc: no
  html_document:
    toc: true
    toc_float: true
    theme: spacelab
---

Name: christina choi

Andrew ID: gawonc

You must submit **your own** HW as a PDF file on Gradescope.

```{r wrap-hook,echo=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
```

---

```{r linewidth=80}
shakespeare.lines = readLines("http://www.andrew.cmu.edu/user/mfarag/shakespeare.txt")
```

---

## Question 1
*(10 points)*

Display the lines of text in `shakespeare.lines` that contain both of the strings "purse" *and* "gold" (in any order, separated by any amount of text). Do so only using regexp literals.
```{r linewidth=80}


grep("purse.*gold|gold.*purse",shakespeare.lines, value=TRUE)  



```

## Question 2
*(10 points)*

Retrieve (but don't display) the lines of text in `shakespeare.lines` that contain "briers". Then break the retrieved lines into individual words (`strsplit(input," ")` to split the character vector `input` into words separated by spaces), and merge those words into a single character vector (`unlist()`!). How many unique words are there? Display the top five most commonly occurring words and how often they occur (combine `sort()` and `table()`!)
```{r linewidth=80}


input = grep("briers",shakespeare.lines, value=TRUE)  

words = strsplit(input," ")

head(table(sort(unlist(words))),5)



```

## Question 3
*(10 points)*

In Q25 of Lab 3, you coded a regex to match all patterns of the following form: any letter (1 or more), then a punctuation mark, then "ve" or "ll" or "t", then a space or a punctuation mark. You called it `my.pattern`. Use `my.pattern`, along with `regexpr()` and `regmatches()`, to extract and display all the occurrences of the pattern in `shakespeare.lines`. Then repeat the exercise using `gregexpr()` instead of `regexpr`; note that here, you'll want to `unlist()` the output from `regmatches()`. Do you get the same vector of character strings? Why or why not?
```{r linewidth=80}
my.pattern = "[A-Za-z]+[[:punct:]](ve|ll|t)( |[[:punct:]])"
occurance =regexpr(my.pattern,shakespeare.lines)
with.regexpr = regmatches(shakespeare.lines, occurance)


occurance2 =gregexpr(my.pattern,shakespeare.lines)
with.gregexpr = unlist(regmatches(shakespeare.lines, occurance2))
with.regexpr
with.gregexpr


```

```
No since regexpr() will only return the first matching substring while gregexpr() will match substrings in a given string.
```

## Question 4
*(10 points)*

Come up with a strategy that splits punctuation marks or spaces, except that it keeps intact words like "I've" or "wasn't", that have a punctuation mark in the middle, in between two letters. (Or when the punctuation mark is at the beginning, as in "'em") Apply your strategy to `shakespeare.lines` as defined below such that you display only those words with punctuation marks. (Note that I end up with 704 [not necessarily unique, but total] words when I implement this strategy. Some include '\"', which we can easily remove in a subsequent post-processing step if we so choose. Hint: `[[:alnum:]]` is a good thing to use here.)
```{r linewidth=80}
new = unlist(strsplit(shakespeare.lines,split="[[:space:]]+"))
punct = "[[:punct:]]"
punctuated.words= grep(punct,new,value=TRUE)
punctuated.words

first = "[[[:alnum:]]*[[:punct:]]+[[:alnum:]]]"


punctuated.words.split=grep("[[:alnum:]]*[[:punct:]]+[[:alnum:]]+",punctuated.words,value=TRUE)
punctuated.words.split

length(punctuated.words.split)
```

---

Below, we read in lines of data from the Advanced National Seismic System (ANSS), on earthquakes of magnitude 6+, between 2002 and 2017. (You don't have to do anything yet.) 
```{r linewidth=80}
anss.lines = readLines("http://www.stat.cmu.edu/~mfarag/350/anss.htm")
date.pattern = "[0-9]{4}/[0-9]{2}/[0-9]{2}"
date.lines = grep(date.pattern,anss.lines,value=TRUE)
```

---

## Question 5
*(10 points)*

Check that all the lines in `date.lines` actually start with a date, of the form YYYY/MM/DD. rather than contain a date of this form somewhere in the middle of the text. (Hint: it might help to note that you can look for non-matches, as opposed to matches, by changing one of `grep()`'s logical arguments.)
```{r linewidth=80}
date.lines

grep("^[0-9]{4}/[0-9]{2}/[0-9]{2}",date.lines,invert=TRUE)

```

## Question 6
*(10 points)*

Which five days witnessed the most earthquakes, and how many were there, these days? Also, what happened on the day with the most earthquakes: can you find any references to this day in the news?
```{r linewidth=80}
first.line = substr(date.lines, 1,10)

sorted = head(sort(table(first.line), decreasing = TRUE),5)
sorted
```
```
Wikipedia states that "The 2011 Tōhoku earthquake and tsunami occurred at 14:46 JST on 11 March. The magnitude 9.0–9.1 undersea megathrust earthquake had an epicenter in the Pacific Ocean, 72 km east of the Oshika Peninsula of the Tōhoku region, and lasted approximately six minutes, causing a tsunami"

```

## Question 7
*(10 points)*

Go back to the data in `date.lines`. Following steps similar to the ones you used in the lab to extract the latitude and longitude of earthquakes, extract the depth and magnitude of earthquakes. In the end, you should have one numeric vector of depths, and one numeric vector of magnitudes. Show the first three depths and the first three magnitudes. (Hint: if you use `regexpr()` and `regmatches()`, then the output from the latter will be a vector of strings. Look at this vector. The last four characters always represent the magnitudes. Use a combination of `substr()` and `as.numeric()` to create the numeric vector of magnitudes. Then use the fact that everything but the last four characters represents the depths. There are a myriad of ways to do this exercise, but this suggested way is the most concise.)


```{r linewidth=80}

depthmag.pair = "[0-9]{1,3}\\.[0-9]{2}[[:space:]][[:space:]][0-9]{1}\\.[0-9]{2}"
reg.exp = regexpr(depthmag.pair,date.lines)

depmag.pairs = regmatches(date.lines,reg.exp)
head(depmag.pairs,3)




```

---

Here we read in text containing the fastest men's 100-meter sprint times. We retain only the lines that correspond to the sprint data, for times 9.99 seconds or better.
```{r linewidth=80}
sprint.lines = readLines("http://www.stat.cmu.edu/~mfarag/350/men_100m.html")
data.lines = grep(" +(9|10)\\.",sprint.lines)
sprint.lines = sprint.lines[min(data.lines):max(data.lines)]
```

---

## Question 8
*(10 points)*

Extract the years in which the sprint times were recorded. Display them in table format. Do the same for the months. Be sure to extract the month of the sprint, not the birth month of the sprinter! (Hint: the month of the sprint is followed by a four-digit year; other instances of two digits in any given line are not. So you may have to extract more than you need, then apply `strsplit()`.)
```{r linewidth=80}

monthyr.pattern = "[0-9]{2}\\.[0-9]{4}"

reg.exp1 = regexpr(monthyr.pattern,sprint.lines)

yearmonth =regmatches(sprint.lines,reg.exp1)

year= substr(yearmonth,4,7)

table(year)
month= substr(yearmonth,1,2)

table(sort(month))

```

## Question 9
*(10 points)*

Extract the countries of origin (for the sprinters). Note that countries of origin are given as a capitalized three-letter abbreviation. Display the table of country origins. Display the proportion of the list that is accounted for by sprinters from the US and Jamaica.
```{r linewidth=80}
country.pattern = "[A-Z]{3}"

reg.exp2 = regexpr(country.pattern,sprint.lines)

country =regmatches(sprint.lines,reg.exp2)

table((country))

length(country)

sprinters.USA = 406/988
sprinters.JAM = 267/988

sprinters.USA  
sprinters.JAM 

total = sprinters.USA  +sprinters.JAM 
total

```

## Question 10
*(10 points)*

We conclude with a web scraping exercise. I want you to go to <a href="https://arxiv.org/year/astro-ph/19">this web site</a>. On it, you see there is a set of 12 bold-faced four-digit numbers: this is the number of submitted astrophysics articles for each month of 2019. I want you to extract these numbers and place them into a single vector, with each vector element having a name: Jan for the first vector element, Feb for the second, etc. You would use `readLines()` to read in the page (pass the URL directly to the function!); this creates a vector of strings. You would then use `regexpr()` and `regmatches()` to extract the numbers (plus potentially some other stuff that you may have to pare off using `substr()`). If necessary, use "view source" to look at the html code for the web page itself to determine how best to extract the 12 numbers and nothing else. You don't want to create a table; you simply want to output the vector of four-digit numbers and add the appropriate names. (Hint: see the documentation for `Constants`. `month.abb` might be helpful here.)

```{r linewidth=80}
astro.lines = readLines("https://arxiv.org/year/astro-ph/19")

bold.letter = regexpr("<b>[0-9]{4}</b>", astro.lines)

asd = regmatches(astro.lines,bold.letter )
asd

final.bold.letter= substr(asd, 4,7)

names(final.bold.letter) <- month.abb
final.bold.letter


```

## Question 11
*(10 points)*

Make a string with "Regards," and then your first name, separated by a newline character. Print it to the console via `print()` and then via `cat()`. Comment on the difference.
```{r linewidth=80}


string = c("Regards,\nChristina")
print(string)
cat(string)


```
```
Printing the string literally prints exactly what I type whereas when I do cat it registers the linebreak.
```

## Question 12
*(10 points)*

Transform the vector so that the words have all uppercase characters.
```{r linewidth=80}


upper = toupper(string)

upper

```
